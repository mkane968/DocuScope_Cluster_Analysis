{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant Directory Files\n",
    "#pd is used for dataframes\n",
    "import pandas as pd\n",
    "#io is used for opening and writing files\n",
    "import io\n",
    "#glob is used to find all the pathnames matching a specified pattern (here, all text files)\n",
    "import glob\n",
    "#os is used to navigate your folder directories (e.g. change folders to where you files are stored)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the file directory \n",
    "filedirectory = '/Users/mkane/Documents/CRA_Research/Background' #Change to place where your individual LAT documents are stored, e.g. '/Users/yourname/Documents/FOLDER'\n",
    "#Change the working directory to the one you just defined\n",
    "os.chdir(filedirectory)\n",
    "#Affirm file directory\n",
    "print (filedirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Bigram Analysis on LAT Sequences\n",
    "for filename in sorted(os.listdir(filedirectory)):\n",
    "    #If the filename ends with .txt (i.e. if it's actually a text files)\n",
    "    if filename.endswith('.txt'):\n",
    "        #Write out below the name of the file\n",
    "        print(filename)\n",
    "        #Open the input filename\n",
    "        with open(filename, 'r') as f:\n",
    "            #Read the contents of the input file\n",
    "            text = f.read()\n",
    "            #Tokenize text in file\n",
    "            tokens = nltk.wordpunct_tokenize(text)\n",
    "            #Define Bigram Finder\n",
    "            finder1 = BigramCollocationFinder.from_words(tokens)\n",
    "            #Score bigram frequency\n",
    "            scored1 = finder1.score_ngrams(bigram_measures.raw_freq)\n",
    "            #Sort bigram frequency\n",
    "            sorted(bigram for bigram, score in scored1)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ten bigrams\n",
    "finder1.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the 10 n-grams with the highest PMI\n",
    "# print (finder1.nbest(bigram_measures.likelihood_ratio, 10))\n",
    "List1=[]\n",
    "for i in finder1.score_ngrams(bigram_measures.likelihood_ratio):\n",
    "    List1.append(i)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List1 =pd.DataFrame.from_records(List1)\n",
    "print(List1)\n",
    "List1.to_csv(\"PMIBigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ngrams scored by manual frequency distribution\n",
    "print(scored1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scored1 =pd.DataFrame.from_records(scored1)\n",
    "print(Scored1)\n",
    "Scored1.to_csv(\"ScoredBigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Trigram Analysis on LAT Sequences\n",
    "for filename in sorted(os.listdir(filedirectory)):\n",
    "    #If the filename ends with .txt (i.e. if it's actually a text files)\n",
    "    if filename.endswith('.txt'):\n",
    "        #Write out below the name of the file\n",
    "        print(filename)\n",
    "        #Open the input filename\n",
    "        with open(filename, 'r') as f:\n",
    "            #Read the contents of the input file\n",
    "            text = f.read()\n",
    "            #Tokenize text in file\n",
    "            tokens = nltk.wordpunct_tokenize(text)\n",
    "            #Define Triigram Finder\n",
    "            finder2 = TrigramCollocationFinder.from_words(tokens)\n",
    "            #Score trigram frequency\n",
    "            scored2 = finder2.score_ngrams(trigram_measures.raw_freq)\n",
    "            #Sort bigram frequency\n",
    "            sorted(trigram for trigram, score in scored)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ten trigrams\n",
    "finder2.nbest(trigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the 10 n-grams with the highest PMI\n",
    "# print (finder1.nbest(bigram_measures.likelihood_ratio, 10))   \n",
    "List2=[]\n",
    "for i in finder2.score_ngrams(trigram_measures.likelihood_ratio):\n",
    "    List2.append(i)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List2 =pd.DataFrame.from_records(List2)\n",
    "print(List2)\n",
    "List2.to_csv(\"PMITrigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ngrams scored by manual frequency distribution\n",
    "print(scored2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scored2 =pd.DataFrame.from_records(scored2)\n",
    "print(Scored2)\n",
    "Scored2.to_csv(\"ScoredTrigrams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
