{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant Directory Files\n",
    "#pd is used for dataframes\n",
    "import pandas as pd\n",
    "#io is used for opening and writing files\n",
    "import io\n",
    "#glob is used to find all the pathnames matching a specified pattern (here, all text files)\n",
    "import glob\n",
    "#os is used to navigate your folder directories (e.g. change folders to where you files are stored)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkane/Documents/CRA_Research/Background\n"
     ]
    }
   ],
   "source": [
    "#Define the file directory \n",
    "filedirectory = '/Users/mkane/Documents/CRA_Research/Background' #Change to place where your individual LAT documents are stored, e.g. '/Users/yourname/Documents/FOLDER'\n",
    "#Change the working directory to the one you just defined\n",
    "os.chdir(filedirectory)\n",
    "#Affirm file directory\n",
    "print (filedirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clsg0021background.txt\n",
      "clsg1011background.txt\n",
      "clsg1021background.txt\n",
      "engg0011background.txt\n",
      "engg0012background.txt\n",
      "engg0021background.txt\n",
      "engg0032background.txt\n",
      "engg0041background.txt\n",
      "engg0063background.txt\n",
      "engg0071background.txt\n",
      "engg0092background.txt\n",
      "engg0161background.txt\n",
      "engg0192background.txt\n",
      "engg0222background.txt\n",
      "engg0312background.txt\n",
      "engg0341background.txt\n",
      "engg0382background.txt\n",
      "engg0401background.txt\n",
      "engg0421background.txt\n",
      "engg0441background.txt\n",
      "engg0511background.txt\n",
      "engg0521background.txt\n",
      "engg1071background.txt\n",
      "engg2021background.txt\n",
      "engg2031background.txt\n",
      "engg2061background.txt\n",
      "hisg0031background.txt\n",
      "hisg0032background.txt\n",
      "hisg0041background.txt\n",
      "hisg1041background.txt\n",
      "hisg1052background.txt\n",
      "hisg2021background.txt\n",
      "hisg3021background.txt\n",
      "ling0041background.txt\n",
      "ling0063background.txt\n",
      "ling0071background.txt\n",
      "ling0072background.txt\n",
      "ling0102background.txt\n",
      "ling1022background.txt\n",
      "ling1064background.txt\n",
      "ling2012background.txt\n",
      "ling2031background.txt\n",
      "phig00121background.txt\n",
      "phig00131background.txt\n",
      "phig00172background.txt\n",
      "phig00181background.txt\n",
      "phig00182background.txt\n",
      "phig00191background.txt\n",
      "phig0022background.txt\n",
      "phig0023background.txt\n",
      "phig0041background.txt\n",
      "phig0065background.txt\n",
      "phig0082background.txt\n"
     ]
    }
   ],
   "source": [
    "#Perform Bigram Analysis on LAT Sequences\n",
    "for filename in sorted(os.listdir(filedirectory)):\n",
    "    #If the filename ends with .txt (i.e. if it's actually a text files)\n",
    "    if filename.endswith('.txt'):\n",
    "        #Write out below the name of the file\n",
    "        print(filename)\n",
    "        #Open the input filename\n",
    "        with open(filename, 'r') as f:\n",
    "            #Read the contents of the input file\n",
    "            text = f.read()\n",
    "            #Tokenize text in file\n",
    "            tokens = nltk.wordpunct_tokenize(text)\n",
    "            #Define Bigram Finder\n",
    "            finder1 = BigramCollocationFinder.from_words(tokens)\n",
    "            #Score bigram frequency\n",
    "            scored1 = finder1.score_ngrams(bigram_measures.raw_freq)\n",
    "            #Sort bigram frequency\n",
    "            sorted(bigram for bigram, score in scored1)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Transformation', 'Immediacy'),\n",
       " ('Citations', 'Contingency'),\n",
       " ('CommonAuthorities', 'Contingency'),\n",
       " ('Contingency', 'CommonAuthorities'),\n",
       " ('Contingency', 'Inclusive'),\n",
       " ('Immediacy', 'PrivateThinking'),\n",
       " ('Inclusive', 'StandardsPos'),\n",
       " ('ReportingEvents', 'StandardsPos'),\n",
       " ('ReportingStates', 'ReportingEvents'),\n",
       " ('StandardsPos', 'GenericEvents')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return top ten bigrams\n",
    "finder1.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the 10 n-grams with the highest PMI\n",
    "# print (finder1.nbest(bigram_measures.likelihood_ratio, 10))\n",
    "List1=[]\n",
    "for i in finder1.score_ngrams(bigram_measures.likelihood_ratio):\n",
    "    List1.append(i)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List1 =pd.DataFrame.from_records(List1)\n",
    "print(List1)\n",
    "List1.to_csv(\"PMIBigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ngrams scored by manual frequency distribution\n",
    "print(scored1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scored1 =pd.DataFrame.from_records(scored1)\n",
    "print(Scored1)\n",
    "Scored1.to_csv(\"ScoredBigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Trigram Analysis on LAT Sequences\n",
    "for filename in sorted(os.listdir(filedirectory)):\n",
    "    #If the filename ends with .txt (i.e. if it's actually a text files)\n",
    "    if filename.endswith('.txt'):\n",
    "        #Write out below the name of the file\n",
    "        print(filename)\n",
    "        #Open the input filename\n",
    "        with open(filename, 'r') as f:\n",
    "            #Read the contents of the input file\n",
    "            text = f.read()\n",
    "            #Tokenize text in file\n",
    "            tokens = nltk.wordpunct_tokenize(text)\n",
    "            #Define Triigram Finder\n",
    "            finder2 = TrigramCollocationFinder.from_words(tokens)\n",
    "            #Score trigram frequency\n",
    "            scored2 = finder2.score_ngrams(trigram_measures.raw_freq)\n",
    "            #Sort bigram frequency\n",
    "            sorted(trigram for trigram, score in scored)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ten trigrams\n",
    "finder2.nbest(trigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the 10 n-grams with the highest PMI\n",
    "# print (finder1.nbest(bigram_measures.likelihood_ratio, 10))   \n",
    "List2=[]\n",
    "for i in finder2.score_ngrams(trigram_measures.likelihood_ratio):\n",
    "    List2.append(i)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List2 =pd.DataFrame.from_records(List2)\n",
    "print(List2)\n",
    "List2.to_csv(\"PMITrigrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return top ngrams scored by manual frequency distribution\n",
    "print(scored2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scored2 =pd.DataFrame.from_records(scored2)\n",
    "print(Scored2)\n",
    "Scored2.to_csv(\"ScoredTrigrams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
